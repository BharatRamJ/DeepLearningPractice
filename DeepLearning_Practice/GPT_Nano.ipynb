{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Jane-Austen Dataset\n",
        "\n",
        "refer: Project Gutenberg\n",
        "https://xpmethod.columbia.edu/knowledge-design-studio/2019-10-26-corpus-db.html"
      ],
      "metadata": {
        "id": "NeufLdi8P0dU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import requests"
      ],
      "metadata": {
        "id": "_mSZXTt7X3uu"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nHPT75DSqStc"
      },
      "outputs": [],
      "source": [
        "# create queries for Corpus-DB\n",
        "baseURL = \"http://corpus-db.org\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getTextAndMeta(author):\n",
        "    metaResponse = requests.get(baseURL+\"/api/author/\"+author)\n",
        "    textResponse = requests.get(baseURL+\"/api/author/\"+author+\"/fulltext\")\n",
        "    meta = json.loads(metaResponse.text)\n",
        "    texts = json.loads(textResponse.text)\n",
        "    return meta, texts"
      ],
      "metadata": {
        "id": "XkRCZsaVX3HX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "austenMeta, austenTexts = getTextAndMeta(\"Austen, Jane\")"
      ],
      "metadata": {
        "id": "fMLYIjxpX7cM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(austenMeta), len(austenTexts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zf19SfHijUEZ",
        "outputId": "de09831f-c4df-402c-8142-a6507d76c666"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[(book['id'], book['title']) for book in austenMeta]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3Yf1MnCjaLh",
        "outputId": "902645a1-44c0-459d-a0ae-b58c565c1d16"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('105.0', 'Persuasion'),\n",
              " ('121.0', 'Northanger Abbey'),\n",
              " ('141.0', 'Mansfield Park'),\n",
              " ('158.0', 'Emma'),\n",
              " ('161.0', 'Sense and Sensibility'),\n",
              " ('946.0', 'Lady Susan'),\n",
              " ('1212.0', 'Love and Freindship [sic]'),\n",
              " ('1342.0', 'Pride and Prejudice'),\n",
              " ('21839.0', 'Sense and Sensibility'),\n",
              " ('25946.0', 'Gevoel en verstand'),\n",
              " ('31100.0',\n",
              "  'The Complete Project Gutenberg Works of Jane Austen: A Linked Index of all PG Editions of Jane Austen'),\n",
              " ('33388.0', \"Raison et sensibilité, ou les deux manières d'aimer (Tome 1)\"),\n",
              " ('35151.0', \"Raison et sensibilité, ou les deux manières d'aimer (Tome 2)\"),\n",
              " ('35163.0', \"Raison et sensibilité, ou les deux manières d'aimer (Tome 3)\"),\n",
              " ('36777.0', 'Persuasion'),\n",
              " ('37431.0', \"Pride and Prejudice, a play founded on Jane Austen's novel\"),\n",
              " ('37634.0', \"Raison et sensibilité, ou les deux manières d'aimer (Tome 4)\"),\n",
              " ('42078.0',\n",
              "  'The Letters of Jane Austen: Selected from the compilation of her great nephew, Edward, Lord Bradbourne'),\n",
              " ('42671.0', 'Pride and Prejudice'),\n",
              " ('45186.0', 'Ylpeys ja ennakkoluulo')]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# keeping only english texts\n",
        "myAustenCollection = [105, 121, 141, 158, 161, 946, 1212, 1342]"
      ],
      "metadata": {
        "id": "hO0XE8JgjfFG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "austenMetaSubset = [book for book in austenMeta if int(float(book['id'])) in myAustenCollection]\n",
        "austenTextSubset = [book for book in austenTexts if int(book['id']) in myAustenCollection]"
      ],
      "metadata": {
        "id": "AT-mlzshjiXQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(austenMetaSubset), len(austenTextSubset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAZ5HA0wjk38",
        "outputId": "68c24943-eace-44d3-8c02-56c92166342a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2586c22c"
      },
      "source": [
        "combined_text = \"\"\n",
        "for book in austenTextSubset:\n",
        "    combined_text += book['text']"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "992a6f9d",
        "outputId": "701476fe-a363-4ebf-a26e-5c93893a9435"
      },
      "source": [
        "import re\n",
        "\n",
        "# Replace sequences of one or more whitespace characters with a single space\n",
        "whitespace_normalized_text = re.sub(r'\\s+', ' ', combined_text)\n",
        "\n",
        "# Strip leading and trailing whitespace\n",
        "whitespace_normalized_text = whitespace_normalized_text.strip()\n",
        "\n",
        "print(f\"Length of combined_text: {len(combined_text)}\")\n",
        "print(f\"Length of whitespace_normalized_text: {len(whitespace_normalized_text)}\")\n",
        "print(f\"First 500 characters of whitespace_normalized_text:\\n{whitespace_normalized_text[:500]}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of combined_text: 4337498\n",
            "Length of whitespace_normalized_text: 4318309\n",
            "First 500 characters of whitespace_normalized_text:\n",
            "by Al Haines. Persuasion by Jane Austen (1818) Chapter 1 Sir Walter Elliot, of Kellynch Hall, in Somersetshire, was a man who, for his own amusement, never took up any book but the Baronetage; there he found occupation for an idle hour, and consolation in a distressed one; there his faculties were roused into admiration and respect, by contemplating the limited remnant of the earliest patents; there any unwelcome sensations, arising from domestic affairs changed naturally into pity and contempt \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "815b8b7b",
        "outputId": "0e7d4cb2-9258-4060-a029-82f1241ee563"
      },
      "source": [
        "cleaned_text = whitespace_normalized_text\n",
        "\n",
        "# Remove specific introductory/concluding phrases\n",
        "cleaned_text = re.sub(r'by Al Haines\\.', '', cleaned_text, flags=re.IGNORECASE)\n",
        "cleaned_text = re.sub(r'Finis', '', cleaned_text, flags=re.IGNORECASE)\n",
        "\n",
        "# Remove Project Gutenberg disclaimers and similar meta-information\n",
        "cleaned_text = re.sub(r'Project Gutenberg-tm is synonymous with the free distribution of electronic texts.', '', cleaned_text, flags=re.IGNORECASE)\n",
        "cleaned_text = re.sub(r'The Project Gutenberg EBook of [^\\.]+\\. This eBook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever\\. You may copy it, give it away or re-use it under the terms of the Project Gutenberg License included with this eBook or online at www\\.gutenberg\\.org', '', cleaned_text, flags=re.IGNORECASE)\n",
        "cleaned_text = re.sub(r'ADVERTISEMENT BY THE AUTHORESS(?:, TO THE SECOND EDITION)?', '', cleaned_text, flags=re.IGNORECASE)\n",
        "cleaned_text = re.sub(r'End of the Project Gutenberg EBook of [^\\.]+\\.', '', cleaned_text, flags=re.IGNORECASE)\n",
        "\n",
        "# Remove book titles and author names that appear as headers/footers but are not part of narrative\n",
        "# This pattern needs to be more careful, but for now, focus on clear header-like structures\n",
        "cleaned_text = re.sub(r'Persuasion by Jane Austen \\(\\d{4}\\)', '', cleaned_text, flags=re.IGNORECASE)\n",
        "cleaned_text = re.sub(r'NORTHANGER ABBEY by Jane Austen \\(\\d{4}\\)', '', cleaned_text, flags=re.IGNORECASE)\n",
        "cleaned_text = re.sub(r'MANSFIELD PARK \\(\\d{4}\\) By Jane Austen', '', cleaned_text, flags=re.IGNORECASE)\n",
        "cleaned_text = re.sub(r'EMMA by Jane Austen \\(\\d{4}\\)', '', cleaned_text, flags=re.IGNORECASE)\n",
        "cleaned_text = re.sub(r'SENSE AND SENSIBILITY by Jane Austen \\(\\d{4}\\)', '', cleaned_text, flags=re.IGNORECASE)\n",
        "cleaned_text = re.sub(r'Lady Susan by Jane Austen \\(\\d{4}\\)', '', cleaned_text, flags=re.IGNORECASE)\n",
        "cleaned_text = re.sub(r'LOVE AND FREINDSHIP \\[sic\\] by Jane Austen \\(\\d{4}\\)', '', cleaned_text, flags=re.IGNORECASE)\n",
        "cleaned_text = re.sub(r'PRIDE AND PREJUDICE By Jane Austen', '', cleaned_text, flags=re.IGNORECASE)\n",
        "\n",
        "\n",
        "# Further normalize whitespace after removals\n",
        "cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
        "\n",
        "print(f\"Length of whitespace_normalized_text: {len(whitespace_normalized_text)}\")\n",
        "print(f\"Length of cleaned_text: {len(cleaned_text)}\")\n",
        "print(f\"First 500 characters of cleaned_text:\\n{cleaned_text[:500]}\")\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of whitespace_normalized_text: 4318309\n",
            "Length of cleaned_text: 4317593\n",
            "First 500 characters of cleaned_text:\n",
            "Chapter 1 Sir Walter Elliot, of Kellynch Hall, in Somersetshire, was a man who, for his own amusement, never took up any book but the Baronetage; there he found occupation for an idle hour, and consolation in a distressed one; there his faculties were roused into admiration and respect, by contemplating the limited remnant of the earliest patents; there any unwelcome sensations, arising from domestic affairs changed naturally into pity and contempt as he turned over the almost endless creations \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bd3f3e2",
        "outputId": "282c75b1-200c-4eb0-d7a9-c95bc11572b5"
      },
      "source": [
        "output_filename = \"austen_combined_cleaned.txt\"\n",
        "with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(cleaned_text)\n",
        "\n",
        "print(f\"Cleaned text saved to {output_filename}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned text saved to austen_combined_cleaned.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bigram Language Model"
      ],
      "metadata": {
        "id": "i43m2RanQN8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('austen_combined_cleaned.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "id": "p5l7iIYTOJNG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"length of dataset in characters: \", len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZOuHP2ROQKZ",
        "outputId": "38e153c5-714d-4eba-9d37-8fdf567e3398"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of dataset in characters:  4317593\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# look at the first 1000 characters\n",
        "print(text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoDGcT_POS26",
        "outputId": "bf1fd8a5-9504-4dbd-b44e-d4551e1540c2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chapter 1 Sir Walter Elliot, of Kellynch Hall, in Somersetshire, was a man who, for his own amusement, never took up any book but the Baronetage; there he found occupation for an idle hour, and consolation in a distressed one; there his faculties were roused into admiration and respect, by contemplating the limited remnant of the earliest patents; there any unwelcome sensations, arising from domestic affairs changed naturally into pity and contempt as he turned over the almost endless creations of the last century; and there, if every other leaf were powerless, he could read his own history with an interest which never failed. This was the page at which the favourite volume always opened: \"ELLIOT OF KELLYNCH HALL. \"Walter Elliot, born March 1, 1760, married, July 15, 1784, Elizabeth, daughter of James Stevenson, Esq. of South Park, in the county of Gloucester, by which lady (who died 1800) he has issue Elizabeth, born June 1, 1785; Anne, born August 9, 1787; a still-born son, November \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unique characters that appear in the text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(''.join(chars))\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgvnjfDYObLD",
        "outputId": "f45ba4a0-6a40-4844-defc-544cb9a898a8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " !\"&'()*,-.0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxyz\n",
            "79\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a mapping from characters to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "print(encode(\"hii there\"))\n",
        "print(decode(encode(\"hii there\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNMp-p_-OhcM",
        "outputId": "e771e92f-bf7f-4036-a64e-4881636cbe59"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[60, 61, 61, 0, 72, 60, 57, 70, 57]\n",
            "hii there\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# encoding the entire data set and storing into Torch.Tensor\n",
        "import torch\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:1000]) # the 1000 characters we looked at earlier will to the GPT look like this"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34b7bP94OmQP",
        "outputId": "7b0cbf69-8065-4b64-cc63-2177c6d16102"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4317593]) torch.int64\n",
            "tensor([26, 60, 53, 68, 72, 57, 70,  0, 12,  0, 42, 61, 70,  0, 46, 53, 64, 72,\n",
            "        57, 70,  0, 28, 64, 64, 61, 67, 72,  8,  0, 67, 58,  0, 34, 57, 64, 64,\n",
            "        77, 66, 55, 60,  0, 31, 53, 64, 64,  8,  0, 61, 66,  0, 42, 67, 65, 57,\n",
            "        70, 71, 57, 72, 71, 60, 61, 70, 57,  8,  0, 75, 53, 71,  0, 53,  0, 65,\n",
            "        53, 66,  0, 75, 60, 67,  8,  0, 58, 67, 70,  0, 60, 61, 71,  0, 67, 75,\n",
            "        66,  0, 53, 65, 73, 71, 57, 65, 57, 66, 72,  8,  0, 66, 57, 74, 57, 70,\n",
            "         0, 72, 67, 67, 63,  0, 73, 68,  0, 53, 66, 77,  0, 54, 67, 67, 63,  0,\n",
            "        54, 73, 72,  0, 72, 60, 57,  0, 25, 53, 70, 67, 66, 57, 72, 53, 59, 57,\n",
            "        22,  0, 72, 60, 57, 70, 57,  0, 60, 57,  0, 58, 67, 73, 66, 56,  0, 67,\n",
            "        55, 55, 73, 68, 53, 72, 61, 67, 66,  0, 58, 67, 70,  0, 53, 66,  0, 61,\n",
            "        56, 64, 57,  0, 60, 67, 73, 70,  8,  0, 53, 66, 56,  0, 55, 67, 66, 71,\n",
            "        67, 64, 53, 72, 61, 67, 66,  0, 61, 66,  0, 53,  0, 56, 61, 71, 72, 70,\n",
            "        57, 71, 71, 57, 56,  0, 67, 66, 57, 22,  0, 72, 60, 57, 70, 57,  0, 60,\n",
            "        61, 71,  0, 58, 53, 55, 73, 64, 72, 61, 57, 71,  0, 75, 57, 70, 57,  0,\n",
            "        70, 67, 73, 71, 57, 56,  0, 61, 66, 72, 67,  0, 53, 56, 65, 61, 70, 53,\n",
            "        72, 61, 67, 66,  0, 53, 66, 56,  0, 70, 57, 71, 68, 57, 55, 72,  8,  0,\n",
            "        54, 77,  0, 55, 67, 66, 72, 57, 65, 68, 64, 53, 72, 61, 66, 59,  0, 72,\n",
            "        60, 57,  0, 64, 61, 65, 61, 72, 57, 56,  0, 70, 57, 65, 66, 53, 66, 72,\n",
            "         0, 67, 58,  0, 72, 60, 57,  0, 57, 53, 70, 64, 61, 57, 71, 72,  0, 68,\n",
            "        53, 72, 57, 66, 72, 71, 22,  0, 72, 60, 57, 70, 57,  0, 53, 66, 77,  0,\n",
            "        73, 66, 75, 57, 64, 55, 67, 65, 57,  0, 71, 57, 66, 71, 53, 72, 61, 67,\n",
            "        66, 71,  8,  0, 53, 70, 61, 71, 61, 66, 59,  0, 58, 70, 67, 65,  0, 56,\n",
            "        67, 65, 57, 71, 72, 61, 55,  0, 53, 58, 58, 53, 61, 70, 71,  0, 55, 60,\n",
            "        53, 66, 59, 57, 56,  0, 66, 53, 72, 73, 70, 53, 64, 64, 77,  0, 61, 66,\n",
            "        72, 67,  0, 68, 61, 72, 77,  0, 53, 66, 56,  0, 55, 67, 66, 72, 57, 65,\n",
            "        68, 72,  0, 53, 71,  0, 60, 57,  0, 72, 73, 70, 66, 57, 56,  0, 67, 74,\n",
            "        57, 70,  0, 72, 60, 57,  0, 53, 64, 65, 67, 71, 72,  0, 57, 66, 56, 64,\n",
            "        57, 71, 71,  0, 55, 70, 57, 53, 72, 61, 67, 66, 71,  0, 67, 58,  0, 72,\n",
            "        60, 57,  0, 64, 53, 71, 72,  0, 55, 57, 66, 72, 73, 70, 77, 22,  0, 53,\n",
            "        66, 56,  0, 72, 60, 57, 70, 57,  8,  0, 61, 58,  0, 57, 74, 57, 70, 77,\n",
            "         0, 67, 72, 60, 57, 70,  0, 64, 57, 53, 58,  0, 75, 57, 70, 57,  0, 68,\n",
            "        67, 75, 57, 70, 64, 57, 71, 71,  8,  0, 60, 57,  0, 55, 67, 73, 64, 56,\n",
            "         0, 70, 57, 53, 56,  0, 60, 61, 71,  0, 67, 75, 66,  0, 60, 61, 71, 72,\n",
            "        67, 70, 77,  0, 75, 61, 72, 60,  0, 53, 66,  0, 61, 66, 72, 57, 70, 57,\n",
            "        71, 72,  0, 75, 60, 61, 55, 60,  0, 66, 57, 74, 57, 70,  0, 58, 53, 61,\n",
            "        64, 57, 56, 10,  0, 43, 60, 61, 71,  0, 75, 53, 71,  0, 72, 60, 57,  0,\n",
            "        68, 53, 59, 57,  0, 53, 72,  0, 75, 60, 61, 55, 60,  0, 72, 60, 57,  0,\n",
            "        58, 53, 74, 67, 73, 70, 61, 72, 57,  0, 74, 67, 64, 73, 65, 57,  0, 53,\n",
            "        64, 75, 53, 77, 71,  0, 67, 68, 57, 66, 57, 56, 21,  0,  2, 28, 35, 35,\n",
            "        32, 38, 43,  0, 38, 29,  0, 34, 28, 35, 35, 48, 37, 26, 31,  0, 31, 24,\n",
            "        35, 35, 10,  0,  2, 46, 53, 64, 72, 57, 70,  0, 28, 64, 64, 61, 67, 72,\n",
            "         8,  0, 54, 67, 70, 66,  0, 36, 53, 70, 55, 60,  0, 12,  8,  0, 12, 18,\n",
            "        17, 11,  8,  0, 65, 53, 70, 70, 61, 57, 56,  8,  0, 33, 73, 64, 77,  0,\n",
            "        12, 16,  8,  0, 12, 18, 19, 15,  8,  0, 28, 64, 61, 78, 53, 54, 57, 72,\n",
            "        60,  8,  0, 56, 53, 73, 59, 60, 72, 57, 70,  0, 67, 58,  0, 33, 53, 65,\n",
            "        57, 71,  0, 42, 72, 57, 74, 57, 66, 71, 67, 66,  8,  0, 28, 71, 69, 10,\n",
            "         0, 67, 58,  0, 42, 67, 73, 72, 60,  0, 39, 53, 70, 63,  8,  0, 61, 66,\n",
            "         0, 72, 60, 57,  0, 55, 67, 73, 66, 72, 77,  0, 67, 58,  0, 30, 64, 67,\n",
            "        73, 55, 57, 71, 72, 57, 70,  8,  0, 54, 77,  0, 75, 60, 61, 55, 60,  0,\n",
            "        64, 53, 56, 77,  0,  5, 75, 60, 67,  0, 56, 61, 57, 56,  0, 12, 19, 11,\n",
            "        11,  6,  0, 60, 57,  0, 60, 53, 71,  0, 61, 71, 71, 73, 57,  0, 28, 64,\n",
            "        61, 78, 53, 54, 57, 72, 60,  8,  0, 54, 67, 70, 66,  0, 33, 73, 66, 57,\n",
            "         0, 12,  8,  0, 12, 18, 19, 16, 22,  0, 24, 66, 66, 57,  8,  0, 54, 67,\n",
            "        70, 66,  0, 24, 73, 59, 73, 71, 72,  0, 20,  8,  0, 12, 18, 19, 18, 22,\n",
            "         0, 53,  0, 71, 72, 61, 64, 64,  9, 54, 67, 70, 66,  0, 71, 67, 66,  8,\n",
            "         0, 37, 67, 74, 57, 65, 54, 57, 70,  0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train-val split\n",
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ],
      "metadata": {
        "id": "yu449FD0Pugb"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8\n",
        "train_data[:block_size+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wuvCrfTQ2A1",
        "outputId": "68ef6783-5b4e-4644-c331-b699f5fc6a65"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([26, 60, 53, 68, 72, 57, 70,  0, 12])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "for t in range(block_size):\n",
        "    context = x[:t+1]\n",
        "    target = y[t]\n",
        "    print(f\"when input is {context} the target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ev7glLqBQ358",
        "outputId": "b278ce8a-4a3b-4653-f25c-7983bf5e935f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is tensor([26]) the target: 60\n",
            "when input is tensor([26, 60]) the target: 53\n",
            "when input is tensor([26, 60, 53]) the target: 68\n",
            "when input is tensor([26, 60, 53, 68]) the target: 72\n",
            "when input is tensor([26, 60, 53, 68, 72]) the target: 57\n",
            "when input is tensor([26, 60, 53, 68, 72, 57]) the target: 70\n",
            "when input is tensor([26, 60, 53, 68, 72, 57, 70]) the target: 0\n",
            "when input is tensor([26, 60, 53, 68, 72, 57, 70,  0]) the target: 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "batch_size = 4 # how many independent sequences will we process in parallel\n",
        "block_size = 8 # what is the maximum context length for predictions\n",
        "\n",
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    return x, y\n",
        "\n",
        "xb, yb = get_batch('train')\n",
        "print('inputs:')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('targets:')\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "\n",
        "print('----')\n",
        "\n",
        "for b in range(batch_size): # batch dimension\n",
        "    for t in range(block_size): # time dimension\n",
        "        context = xb[b, :t+1]\n",
        "        target = yb[b,t]\n",
        "        print(f\"when input is {context.tolist()} the target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBlx-gLoRDWO",
        "outputId": "374e418f-6bc8-4359-c4aa-f16eb4b3f53d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs:\n",
            "torch.Size([4, 8])\n",
            "tensor([[56, 57, 70,  0, 53,  0, 55, 67],\n",
            "        [61, 59, 60, 54, 73, 70, 77,  0],\n",
            "        [66, 57, 71, 72, 64, 77,  0, 72],\n",
            "        [70, 55, 77, 23,  2,  0, 31, 57]])\n",
            "targets:\n",
            "torch.Size([4, 8])\n",
            "tensor([[57, 70,  0, 53,  0, 55, 67, 66],\n",
            "        [59, 60, 54, 73, 70, 77,  0, 60],\n",
            "        [57, 71, 72, 64, 77,  0, 72, 70],\n",
            "        [55, 77, 23,  2,  0, 31, 57,  0]])\n",
            "----\n",
            "when input is [56] the target: 57\n",
            "when input is [56, 57] the target: 70\n",
            "when input is [56, 57, 70] the target: 0\n",
            "when input is [56, 57, 70, 0] the target: 53\n",
            "when input is [56, 57, 70, 0, 53] the target: 0\n",
            "when input is [56, 57, 70, 0, 53, 0] the target: 55\n",
            "when input is [56, 57, 70, 0, 53, 0, 55] the target: 67\n",
            "when input is [56, 57, 70, 0, 53, 0, 55, 67] the target: 66\n",
            "when input is [61] the target: 59\n",
            "when input is [61, 59] the target: 60\n",
            "when input is [61, 59, 60] the target: 54\n",
            "when input is [61, 59, 60, 54] the target: 73\n",
            "when input is [61, 59, 60, 54, 73] the target: 70\n",
            "when input is [61, 59, 60, 54, 73, 70] the target: 77\n",
            "when input is [61, 59, 60, 54, 73, 70, 77] the target: 0\n",
            "when input is [61, 59, 60, 54, 73, 70, 77, 0] the target: 60\n",
            "when input is [66] the target: 57\n",
            "when input is [66, 57] the target: 71\n",
            "when input is [66, 57, 71] the target: 72\n",
            "when input is [66, 57, 71, 72] the target: 64\n",
            "when input is [66, 57, 71, 72, 64] the target: 77\n",
            "when input is [66, 57, 71, 72, 64, 77] the target: 0\n",
            "when input is [66, 57, 71, 72, 64, 77, 0] the target: 72\n",
            "when input is [66, 57, 71, 72, 64, 77, 0, 72] the target: 70\n",
            "when input is [70] the target: 55\n",
            "when input is [70, 55] the target: 77\n",
            "when input is [70, 55, 77] the target: 23\n",
            "when input is [70, 55, 77, 23] the target: 2\n",
            "when input is [70, 55, 77, 23, 2] the target: 0\n",
            "when input is [70, 55, 77, 23, 2, 0] the target: 31\n",
            "when input is [70, 55, 77, 23, 2, 0, 31] the target: 57\n",
            "when input is [70, 55, 77, 23, 2, 0, 31, 57] the target: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# input to the model\n",
        "print(xb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2p6B1GQmRG1K",
        "outputId": "c3d248ae-f7ba-4244-c997-93609919d10d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[56, 57, 70,  0, 53,  0, 55, 67],\n",
            "        [61, 59, 60, 54, 73, 70, 77,  0],\n",
            "        [66, 57, 71, 72, 64, 77,  0, 72],\n",
            "        [70, 55, 77, 23,  2,  0, 31, 57]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "m = BigramLanguageModel(vocab_size)\n",
        "logits, loss = m(xb, yb)\n",
        "print(logits.shape)\n",
        "print(loss)\n",
        "\n",
        "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8PZEyTlRMVv",
        "outputId": "9bdd32ab-1bed-463d-b7ad-e2835d58a306"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 79])\n",
            "tensor(4.6063, grad_fn=<NllLossBackward0>)\n",
            " D.(CHWmYgV6CiL4Q8k]MKC,?'pSZ2RvV3_rgj-3wI: HE-sTbK?(Sd7xk-T1c5n:u,._ykK?2PQYVIs]o,k!nZ\"U5fY0vDH4bhcK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "BmzuRHkzRPZE"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "for steps in range(10000): # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(loss.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oDS6TngRb6K",
        "outputId": "32edadd5-5860-4787-dbcf-5ff3cb1c1971"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3879520893096924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sampling from the output\n",
        "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiSzB0zTRiuA",
        "outputId": "aa37e3c5-8e63-4f79-97c0-5212324a0ad6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ofouly te, caroor varsug ave \"f wherenorotthitheat om iourtowiaswangir t villllwn omambestrecod t.\"tho hind d Mivese. s Bry henoushas insorughongge; bldnecug. thinourellyey tortyisg oualise--fennend, hisUurets icutot hioober, unsul e urigr thadit I wr.--nllasendgit d Sh ul nemy Thel---mon blm, d, Mr anthig thepatoritalyof l bu wind osteverenime otabeald ccllad by \" o artimpohe cicathild Jurs ovelWe pldontls, teras t nd weay suppreat sout Heanok anchilnwhinde. pe d gicalknd sh warice oc:4Byer ath\n"
          ]
        }
      ]
    }
  ]
}