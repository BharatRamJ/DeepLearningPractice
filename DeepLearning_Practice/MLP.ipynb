{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eINnjzWRbFn4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt # for making figures\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = open('names.txt', 'r').read().splitlines()\n",
        "words[:8]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BV8UkDLlgvTb",
        "outputId": "c7a06f36-21b6-4596-95a6-3e2a95a2153e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DdCHscjhA7u",
        "outputId": "cad5db93-207d-4e2a-a93c-f18e06483c6d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32033"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build the vocabulary of characters and mappings to/from integers\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "print(itos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GrpXF6Lj5Qu",
        "outputId": "7e459c8d-68a5-48e3-81f2-ec644f3ed7c1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build the dataset\n",
        "\n",
        "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
        "X, Y = [], []\n",
        "for w in words[:5]:\n",
        "\n",
        "  print(w)\n",
        "  context = [0] * block_size\n",
        "  for ch in w + '.':\n",
        "    ix = stoi[ch]\n",
        "    X.append(context)\n",
        "    Y.append(ix)\n",
        "    print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
        "    context = context[1:] + [ix] # crop and append\n",
        "\n",
        "X = torch.tensor(X)\n",
        "Y = torch.tensor(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVxlktIoj6V4",
        "outputId": "f56ffa25-54e8-4e91-f43e-24f157d820f7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emma\n",
            "... ---> e\n",
            "..e ---> m\n",
            ".em ---> m\n",
            "emm ---> a\n",
            "mma ---> .\n",
            "olivia\n",
            "... ---> o\n",
            "..o ---> l\n",
            ".ol ---> i\n",
            "oli ---> v\n",
            "liv ---> i\n",
            "ivi ---> a\n",
            "via ---> .\n",
            "ava\n",
            "... ---> a\n",
            "..a ---> v\n",
            ".av ---> a\n",
            "ava ---> .\n",
            "isabella\n",
            "... ---> i\n",
            "..i ---> s\n",
            ".is ---> a\n",
            "isa ---> b\n",
            "sab ---> e\n",
            "abe ---> l\n",
            "bel ---> l\n",
            "ell ---> a\n",
            "lla ---> .\n",
            "sophia\n",
            "... ---> s\n",
            "..s ---> o\n",
            ".so ---> p\n",
            "sop ---> h\n",
            "oph ---> i\n",
            "phi ---> a\n",
            "hia ---> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, Y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeziRju0lRfa",
        "outputId": "56c090f9-e4e4-4ee9-8a43-77ea0a7b21a4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 3]), torch.Size([32]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# C is the embedding vector\n",
        "C = torch.randn((27, 2))\n",
        "C.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElFMEFV7ljap",
        "outputId": "47fd1577-7206-45cf-cb2f-8d1c871ada13"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C[5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPFpSvb1npOR",
        "outputId": "3788aedc-5a16-4222-b161-c94283666b2d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.7560,  0.6801])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F.one_hot(torch.tensor(5), num_classes=27).float() @ C"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wStr3bWnqad",
        "outputId": "404223c2-987c-48a7-8700-d298adb44520"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.7560,  0.6801])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# how to embed all the 32, 3 input\n",
        "C[X].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wauuMnKcn842",
        "outputId": "eaab533c-a374-412e-f09f-4ed0b4452481"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzc_SEDdrsru",
        "outputId": "6becdada-46c3-4263-b03d-ab743e234cc0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.2064, -1.7771])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[13, 2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Z_wBe0lruiN",
        "outputId": "6678afeb-2a1a-45b1-d06a-8761265a7f30"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C[X][13, 2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIXetvNFt9pH",
        "outputId": "fb918c78-f850-4f7c-c70b-3ef5d6c6cb8f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.2064, -1.7771])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding\n",
        "emb = C[X]\n",
        "emb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qnqb9w0PuSk8",
        "outputId": "5487187a-7ed7-4e5b-8670-13e5c5277249"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we have 2 dimensional embedding and 3 of them, so input to w2 is 6 and arbitrarily lets take 100 neurons\n",
        "w1 = torch.randn((6, 100))\n",
        "b1 = torch.randn((100, ))\n",
        "\n",
        "# emb: [32, 3, 2], w1: [6, 100]\n",
        "# how to transform the embedding to match the dimensions of w1 - concatenation\n",
        "emb[:, 0, :].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-q_Mr447uUus",
        "outputId": "8191309d-0457-4bdd-c4af-e94adb9d36fa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cat([emb[:, 0, :], emb[:, 1, :], emb[:, 2, :]], 1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1swuMtnGAK-",
        "outputId": "7ad0f01f-2550-4349-e676-113e7bbe130b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "But using cat is not scalable as we are directly indexing, so instead we use unbind."
      ],
      "metadata": {
        "id": "4xHOvFkqGY0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cat(torch.unbind(emb, 1), 1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpLSH19BGx6C",
        "outputId": "86ae1c79-695b-4178-a2fd-faa03c809f38"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb.view(32, 6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waz_WxdNHB5R",
        "outputId": "b2e0a599-c6a2-4348-a8c9-5eb9bc2f8d1b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.5031,  0.3500, -1.5031,  0.3500, -1.5031,  0.3500],\n",
              "        [-1.5031,  0.3500, -1.5031,  0.3500, -0.7560,  0.6801],\n",
              "        [-1.5031,  0.3500, -0.7560,  0.6801, -0.9531,  0.4204],\n",
              "        [-0.7560,  0.6801, -0.9531,  0.4204, -0.9531,  0.4204],\n",
              "        [-0.9531,  0.4204, -0.9531,  0.4204,  0.2064, -1.7771],\n",
              "        [-1.5031,  0.3500, -1.5031,  0.3500, -1.5031,  0.3500],\n",
              "        [-1.5031,  0.3500, -1.5031,  0.3500, -0.8420, -0.2216],\n",
              "        [-1.5031,  0.3500, -0.8420, -0.2216, -0.8775, -0.5369],\n",
              "        [-0.8420, -0.2216, -0.8775, -0.5369,  0.6727, -1.1821],\n",
              "        [-0.8775, -0.5369,  0.6727, -1.1821, -2.0961,  0.2567],\n",
              "        [ 0.6727, -1.1821, -2.0961,  0.2567,  0.6727, -1.1821],\n",
              "        [-2.0961,  0.2567,  0.6727, -1.1821,  0.2064, -1.7771],\n",
              "        [-1.5031,  0.3500, -1.5031,  0.3500, -1.5031,  0.3500],\n",
              "        [-1.5031,  0.3500, -1.5031,  0.3500,  0.2064, -1.7771],\n",
              "        [-1.5031,  0.3500,  0.2064, -1.7771, -2.0961,  0.2567],\n",
              "        [ 0.2064, -1.7771, -2.0961,  0.2567,  0.2064, -1.7771],\n",
              "        [-1.5031,  0.3500, -1.5031,  0.3500, -1.5031,  0.3500],\n",
              "        [-1.5031,  0.3500, -1.5031,  0.3500,  0.6727, -1.1821],\n",
              "        [-1.5031,  0.3500,  0.6727, -1.1821,  0.7781, -0.2078],\n",
              "        [ 0.6727, -1.1821,  0.7781, -0.2078,  0.2064, -1.7771],\n",
              "        [ 0.7781, -0.2078,  0.2064, -1.7771, -1.9752,  1.0343],\n",
              "        [ 0.2064, -1.7771, -1.9752,  1.0343, -0.7560,  0.6801],\n",
              "        [-1.9752,  1.0343, -0.7560,  0.6801, -0.8775, -0.5369],\n",
              "        [-0.7560,  0.6801, -0.8775, -0.5369, -0.8775, -0.5369],\n",
              "        [-0.8775, -0.5369, -0.8775, -0.5369,  0.2064, -1.7771],\n",
              "        [-1.5031,  0.3500, -1.5031,  0.3500, -1.5031,  0.3500],\n",
              "        [-1.5031,  0.3500, -1.5031,  0.3500,  0.7781, -0.2078],\n",
              "        [-1.5031,  0.3500,  0.7781, -0.2078, -0.8420, -0.2216],\n",
              "        [ 0.7781, -0.2078, -0.8420, -0.2216, -1.2177,  0.5796],\n",
              "        [-0.8420, -0.2216, -1.2177,  0.5796, -0.3953,  0.0258],\n",
              "        [-1.2177,  0.5796, -0.3953,  0.0258,  0.6727, -1.1821],\n",
              "        [-0.3953,  0.0258,  0.6727, -1.1821,  0.2064, -1.7771]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhTtSiRIJMNA",
        "outputId": "7204252c-b5cd-494a-940e-7c0a58c35ea6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h = torch.tanh(emb.view(-1, 6) @ w1 + b1) # -1 is equivalent to emb.shape[0]."
      ],
      "metadata": {
        "id": "49s95bq6IzZh"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yscPitEJTou",
        "outputId": "93da865a-5b0b-4b1d-b3d5-22130055671e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.9999,  0.9648,  0.7827,  ...,  0.9994,  0.9998,  0.9891],\n",
              "        [-0.9997,  0.9779,  0.4883,  ...,  0.9990,  0.9999,  0.9842],\n",
              "        [-0.9992,  0.5573,  0.8894,  ...,  0.9997,  0.9998,  0.9941],\n",
              "        ...,\n",
              "        [-0.9959,  0.8495, -0.3119,  ...,  0.9974,  0.9965,  0.3274],\n",
              "        [-0.9973, -0.9518, -0.2297,  ...,  0.9899,  0.8125,  0.1902],\n",
              "        [-0.9367, -0.9988, -0.8933,  ..., -0.9684, -0.9785, -0.9010]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2 = torch.randn((100, 27))\n",
        "b2 = torch.randn(27)\n",
        "\n",
        "logits = h @ w2 + b2\n",
        "logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6-nt6rjJXMX",
        "outputId": "f903a97f-296b-4893-d238-a56d65379df3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts = logits.exp()\n",
        "prob = counts / (counts.sum(1, keepdims=True))\n",
        "prob[0].sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd6JnufAMKjI",
        "outputId": "bfa0be5f-7150-40a9-9d92-6c587be05295"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prob[torch.arange(32), Y]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvfQlmKxMcX8",
        "outputId": "4531bbd4-da36-441e-ee95-9fcaa03ea764"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7.9524e-08, 1.6542e-09, 1.8354e-08, 6.7632e-05, 4.8770e-12, 1.9873e-08,\n",
              "        1.3499e-11, 8.2946e-09, 1.5892e-07, 1.7344e-07, 3.5211e-06, 7.6723e-11,\n",
              "        1.1308e-04, 1.3741e-06, 5.0086e-01, 4.3359e-11, 1.0816e-06, 2.4611e-09,\n",
              "        9.9195e-01, 8.9437e-06, 4.8039e-08, 1.4496e-05, 6.2966e-12, 9.9932e-01,\n",
              "        6.1804e-11, 6.1928e-08, 2.2616e-07, 6.4309e-07, 1.8849e-13, 5.0059e-08,\n",
              "        5.5715e-01, 2.6736e-10])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = -prob[torch.arange(32), Y].log().mean()\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SW3t3alGNEL7",
        "outputId": "e375645d-ade7-4f31-e2f0-3c5d2445b645"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(15.7182)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l = F.cross_entropy(logits, Y) # much more efficient than writing our own code, as new tenors are not created in memory.\n",
        "l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwZvyC98Pqyf",
        "outputId": "e0fc00f3-0daa-4c1a-fdce-cf3c3fa8f941"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(15.7182)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train, test and validation split up\n",
        "def build_dataset(words):\n",
        "  X, Y = [], []\n",
        "\n",
        "  for w in words:\n",
        "    context = [0] * block_size\n",
        "    for ch in w + '.':\n",
        "      ix = stoi[ch]\n",
        "      X.append(context)\n",
        "      Y.append(ix)\n",
        "      context = context[1:] + [ix] # crop and append\n",
        "\n",
        "  X = torch.tensor(X)\n",
        "  Y = torch.tensor(Y)\n",
        "  print(X.shape, Y.shape)\n",
        "  return X, Y\n",
        "\n",
        "import random\n",
        "random.seed(42)\n",
        "random.shuffle(words)\n",
        "n1 = int(0.8*len(words))\n",
        "n2 = int(0.9*len(words))\n",
        "\n",
        "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
        "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
        "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGrzgopYuvcm",
        "outputId": "94a3463c-2e58-4faf-e073-b40208a49383"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([182580, 3]) torch.Size([182580])\n",
            "torch.Size([22767, 3]) torch.Size([22767])\n",
            "torch.Size([22799, 3]) torch.Size([22799])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4-dimensional issue in starting loss being very high\n",
        "logits = torch.tensor([0.0, 0.0, 5.0, 0.0])\n",
        "probs = torch.softmax(logits, dim=0)\n",
        "loss = -probs[2].log()\n",
        "\n",
        "probs, loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8nkVwvKu5TX",
        "outputId": "b6e650e4-d599-45bb-8cf3-c2d76e5d09e5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.0066, 0.0066, 0.9802, 0.0066]), tensor(0.0200))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(itos)\n",
        "\n",
        "# MLP revisited\n",
        "n_embd = 10 # the dimensionality of the character embedding vectors\n",
        "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
        "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
        "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g)\n",
        "b1 = torch.randn(n_hidden,                        generator=g)\n",
        "W2 = torch.randn((n_hidden, vocab_size),          generator=g)\n",
        "b2 = torch.randn(vocab_size,                      generator=g)\n",
        "\n",
        "parameters = [C, W1, b1, W2, b2]\n",
        "print(sum(p.nelement() for p in parameters))\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vswmQK3vyP2g",
        "outputId": "644640cf-b4a2-4fa1-c90b-d80cd7406d2e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# same optimization as last time\n",
        "max_steps = 200000\n",
        "batch_size = 32\n",
        "lossi = []\n",
        "\n",
        "for i in range(max_steps):\n",
        "\n",
        "  # minibatch construct\n",
        "  ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
        "  Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
        "\n",
        "  # forward pass\n",
        "  emb = C[Xb] # embed the characters into vectors\n",
        "  embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
        "  # Linear layer\n",
        "  hpreact = embcat @ W1 + b1 # hidden layer pre-activation\n",
        "  # Non-linearity\n",
        "  h = torch.tanh(hpreact) # hidden layer\n",
        "  logits = h @ W2 + b2 # output layer\n",
        "  loss = F.cross_entropy(logits, Yb) # loss function\n",
        "\n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  # update\n",
        "  lr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n",
        "  for p in parameters:\n",
        "    p.data += -lr * p.grad\n",
        "\n",
        "  # track stats\n",
        "  if i % 10000 == 0: # print every once in a while\n",
        "    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
        "  lossi.append(loss.log10().item())\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDD6f3O5yvYx",
        "outputId": "0fe12990-abbe-4522-d398-5a472a040540"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      0/ 200000: 26.5404\n",
            "  10000/ 200000: 2.8297\n",
            "  20000/ 200000: 2.5702\n",
            "  30000/ 200000: 2.2293\n",
            "  40000/ 200000: 2.3720\n",
            "  50000/ 200000: 2.7074\n",
            "  60000/ 200000: 2.3786\n",
            "  70000/ 200000: 2.3498\n",
            "  80000/ 200000: 2.1334\n",
            "  90000/ 200000: 2.0449\n",
            " 100000/ 200000: 2.3394\n",
            " 110000/ 200000: 2.3778\n",
            " 120000/ 200000: 2.2828\n",
            " 130000/ 200000: 2.4198\n",
            " 140000/ 200000: 2.2789\n",
            " 150000/ 200000: 2.2704\n",
            " 160000/ 200000: 2.1293\n",
            " 170000/ 200000: 2.1585\n",
            " 180000/ 200000: 2.4126\n",
            " 190000/ 200000: 2.0491\n"
          ]
        }
      ]
    }
  ]
}